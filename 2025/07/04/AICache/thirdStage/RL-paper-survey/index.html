<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>RL paper survey | Hexo</title><meta name="author" content="Bo Han"><meta name="copyright" content="Bo Han"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="1. ArtMem ArtMem：Adaptive Migration in Reinforcement Learning-Enabled Tiered Memory 背景： 内存系统只靠 DRAM 不足，因此引入 PM 和基于 CXL 的额外内存，形成快慢速的分层内存系统。 但现有分层内存系统中的页面迁移策略不够 adaptive，没有充分考虑到工作负载的动态性，因此引入强化学习策略。 内存访问">
<meta property="og:type" content="article">
<meta property="og:title" content="RL paper survey">
<meta property="og:url" content="https://lingwu-hb.github.io/2025/07/04/AICache/thirdStage/RL-paper-survey/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1. ArtMem ArtMem：Adaptive Migration in Reinforcement Learning-Enabled Tiered Memory 背景： 内存系统只靠 DRAM 不足，因此引入 PM 和基于 CXL 的额外内存，形成快慢速的分层内存系统。 但现有分层内存系统中的页面迁移策略不够 adaptive，没有充分考虑到工作负载的动态性，因此引入强化学习策略。 内存访问">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://lingwu-hb.github.io/img/yaojie.jpg">
<meta property="article:published_time" content="2025-07-04T02:03:02.000Z">
<meta property="article:modified_time" content="2025-11-04T11:50:50.886Z">
<meta property="article:author" content="Bo Han">
<meta property="article:tag" content="实习项目">
<meta property="article:tag" content="algorithm">
<meta property="article:tag" content="RL">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lingwu-hb.github.io/img/yaojie.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "RL paper survey",
  "url": "https://lingwu-hb.github.io/2025/07/04/AICache/thirdStage/RL-paper-survey/",
  "image": "https://lingwu-hb.github.io/img/yaojie.jpg",
  "datePublished": "2025-07-04T02:03:02.000Z",
  "dateModified": "2025-11-04T11:50:50.886Z",
  "author": [
    {
      "@type": "Person",
      "name": "Bo Han",
      "url": "https://lingwu-hb.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://lingwu-hb.github.io/2025/07/04/AICache/thirdStage/RL-paper-survey/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;500;700&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'RL paper survey',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.2.0"></head><body><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Hexo</span></a><a class="nav-page-title" href="/"><span class="site-name">RL paper survey</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">RL paper survey</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-07-04T02:03:02.000Z" title="Created 2025-07-04 10:03:02">2025-07-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-11-04T11:50:50.886Z" title="Updated 2025-11-04 19:50:50">2025-11-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/paper/">paper</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/data-storage/">data storage</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="1-ArtMem">1. ArtMem</h1>
<p>ArtMem：Adaptive Migration in Reinforcement Learning-Enabled Tiered Memory</p>
<h2 id="背景：">背景：</h2>
<p>内存系统只靠 DRAM 不足，因此引入 PM 和基于 CXL 的额外内存，形成快慢速的分层内存系统。</p>
<p>但现有分层内存系统中的页面迁移策略不够 adaptive，没有充分考虑到工作负载的动态性，因此引入强化学习策略。</p>
<h3 id="内存访问监控">内存访问监控</h3>
<p>内存访问监控方面一般有三种方式：页表扫描、页错误捕捉、硬件事件采样。</p>
<p>页表扫描通过检查页面表访问位获取访问信息，但扫描开销高，尤其在页面数量庞大时；</p>
<p>页错误捕捉仅监控未命中的页面，信息不完整；</p>
<p>硬件事件采样利用CPU的性能监控单元（PMU）和精确事件采样（PEBS），以低开销捕获全面的访问数据。但是存在硬件依赖。</p>
<p>ArtMem选择第三种方式，通过每个CPU核心的采样线程收集页面访问地址和频率，存储在环形缓冲区，结合指数桶（以2为底）和冷却操作（每200万样本减半计数），高效跟踪访问分布。</p>
<h3 id="页迁移指标">页迁移指标</h3>
<p>页面迁移需要决策是迁移掉访问频率低的，还是迁移掉最近未访问过的？</p>
<p>ArtMem综合考虑访问频率和最近性，以更准确地识别热页面。</p>
<p>最近性通过Linux的活跃页面列表（active list）和非活跃页面列表（inactive list）获取，基于LRU（最近最少使用）机制。</p>
<p>访问频率通过指数移动平均（EMA）计算，平滑短期波动，反映页面的长期访问趋势。</p>
<p>EMA 值反映了频率和最近性的结合。EMA 公式一般来说如下所示。<br>
$$<br>
EMA_t = α·Access_t + (1-α)·EMA_{t-1}<br>
$$<br>
其中，<code>Access_t</code>是当前时间步的访问频率，<code>α</code>是平滑因子，<code>EMA_t</code>是前一时间步的EMA值。</p>
<h3 id="DRAM-快速访问比例">DRAM 快速访问比例</h3>
<p>DRAM 访问比例可以实时反映内存利用率。利用该信息，可以做出一些更加针对性的页放置决策。</p>
<p>因此将此指标设计为强化学习的状态参数。</p>
<h3 id="页迁移范围">页迁移范围</h3>
<p>页迁移范围也是一个比较重要的指标，因此也将其和热页面阈值一起，作为 RL 调节的环境对象属性。</p>
<h2 id="ArtMem-设计">ArtMem 设计</h2>
<p>ArtMem 是一个基于强化学习（RL）的分层内存管理框架，旨在通过动态页面迁移优化内存密集型应用的性能。本文将深入探讨 ArtMem 的强化学习设计，分析其状态、动作、奖励机制以及 Q-learning 实现，揭示其如何通过学习适应复杂内存访问模式。</p>
<h3 id="1-强化学习框架概述">1. 强化学习框架概述</h3>
<p>ArtMem 采用 <strong>Q-learning</strong> 作为核心强化学习算法，这是一种无模型（model-free）的方法，通过与环境的交互学习最优策略。RL 框架的五个关键组件（代理、环境、状态、动作、奖励）在 ArtMem 中被精心设计，以适应分层内存系统的动态需求。以下是 ArtMem RL 框架的核心组成：</p>
<table>
<thead>
<tr>
<th>RL 组件</th>
<th>ArtMem 设计</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>代理（Agent）</strong></td>
<td>运行在 Linux 内核中的 RL 控制器，负责决策页面迁移策略。</td>
</tr>
<tr>
<td><strong>环境（Environment）</strong></td>
<td>分层内存系统（DRAM 和 PM），通过 PMU 和 PEBS 提供内存访问信息。</td>
</tr>
<tr>
<td><strong>状态（State）</strong></td>
<td>离散化的 DRAM 访问比率（DRAM access ratio）。</td>
</tr>
<tr>
<td><strong>动作（Action）</strong></td>
<td>调节热页面阈值和页面迁移数量。</td>
</tr>
<tr>
<td><strong>奖励（Reward）</strong></td>
<td>基于 DRAM 访问比率变化和迁移成本的组合奖励函数。</td>
</tr>
</tbody>
</table>
<p>ArtMem 的 RL 设计目标是最大化快速内存（DRAM）的访问比率，同时最小化不必要的页面迁移开销。通过动态调整迁移策略，ArtMem 能够适应不同工作负载的内存访问模式，显著提升性能（论文中提到平均性能提升 114%）。</p>
<h3 id="2-状态设计">2. 状态设计</h3>
<h4 id="2-1-定义">2.1 定义</h4>
<p>ArtMem 使用 <strong>DRAM 访问比率</strong>（DRAM access ratio）作为状态的唯一指标，表示内存访问中 DRAM 的占比。公式如下：<br>
$$<br>
[r = \frac{\text{DRAM}<em>{\text{access}} \times k}{\text{DRAM}</em>{\text{access}} + \text{PM}_{\text{access}}}]<br>
$$</p>
<ul>
<li>$DRAM{access}$：快速内存（DRAM）的访问次数。</li>
<li>$PM_{access}$：慢速内存（PM）的访问次数。</li>
<li>$k$：离散化参数，将连续的访问比率映射到 11 个离散状态（0 到 10）。</li>
</ul>
<p>此外，ArtMem 为特殊情况（例如 $(\text{DRAM}<em>{\text{access}} = \text{PM}</em>{\text{access}} = 0)$，即访问全部命中 CPU 缓存或无事件发生）设置了一个额外状态（(k = 11)），共 12 个状态。</p>
<h4 id="2-2-设计考量">2.2 设计考量</h4>
<ul>
<li><strong>系统级状态</strong>：ArtMem 选择系统级别的 DRAM 访问比率，而不是逐页状态，以降低计算复杂度和 Q 表开销。论文指出，逐页状态会导致 Q 表过大，减慢学习速度。</li>
<li><strong>离散化</strong>：将连续的访问比率离散化为 12 个状态，平衡了状态空间的表达能力与计算效率。(k = 10) 是经验上的最优值，过多或过少状态都会影响性能。</li>
<li><strong>实时性</strong>：通过 PMU 和 PEBS 采样，状态更新能够实时反映内存访问模式的变化，确保 RL 代理对环境变化的敏感性。</li>
</ul>
<h3 id="3-动作设计">3. 动作设计</h3>
<p>ArtMem 定义了两组动作，分别控制迁移策略的两个关键参数：</p>
<ol>
<li><strong>调节热页面阈值</strong>：
<ul>
<li>动作集合：{+8, +4, 0, -4, -8}，表示对热页面阈值的调整步长。</li>
<li>热页面阈值决定了哪些页面被认为是“热”页面，符合条件的页面才会被迁移到 DRAM。</li>
<li>最小阈值设为 0.5（经验值），避免探索阶段设置过低阈值导致大量无效迁移（见第 5 节）。</li>
</ul>
</li>
<li><strong>调节页面迁移数量</strong>：
<ul>
<li>动作集合：{0MB, 16MB, 32MB, 64MB, 128MB, 256MB, 512MB, 1024MB, 2048MB}。</li>
<li>迁移单位为 2MB 大页面（huge page），以减少地址转换开销。</li>
<li>0MB 表示不进行迁移，用于避免不必要的迁移开销。</li>
</ul>
</li>
</ol>
<h4 id="3-1-动作空间优化">3.1 动作空间优化</h4>
<ul>
<li><strong>两张 Q 表</strong>：ArtMem 使用两张独立的 Q 表分别控制热页面阈值和迁移数量，允许两者协同优化。这种分离设计降低了单一 Q 表的维度，提高了学习效率。</li>
<li><strong>动作粒度</strong>：迁移数量从 16MB 到 2048MB 呈倍数增长，覆盖了从小规模到大规模迁移的场景，适合不同工作负载的动态需求。</li>
<li><strong>探索与利用</strong>：通过 ε-贪心策略（$(\varepsilon = 0.5)$），ArtMem 在探索新动作和利用已有知识之间取得平衡。($\varepsilon = 0.5$) 是经验上的最优值。</li>
</ul>
<h3 id="4-奖励设计">4. 奖励设计</h3>
<p>奖励函数是 ArtMem RL 框架的核心，指导代理学习最优迁移策略。论文中定义的奖励函数如下：</p>
<p>$$[\text{Reward} = \tau_i - \beta + \lambda (\tau_i - \tau_{i-1})]$$</p>
<ul>
<li><strong>$(\tau_i)$</strong>：当前时间步的 DRAM 访问比率（实际值）。</li>
<li><strong>$(\beta)$</strong>：预期的 DRAM 访问比率（经验参数，范围 1-10）。</li>
<li><strong>$(\lambda)$</strong>：二值参数，0 表示未发生迁移，1 表示发生迁移。</li>
<li><strong>$(\tau_i - \tau_{i-1})$</strong>：DRAM 访问比率的变化，反映迁移效果。</li>
</ul>
<h4 id="4-1-奖励函数解析">4.1 奖励函数解析</h4>
<ul>
<li><strong>目标</strong>：奖励函数鼓励将热页面迁移到 DRAM 以提高 ($\tau_i$)，同时通过 ($\lambda$) 惩罚不必要的迁移（迁移成本）。</li>
<li><strong>$(\beta)$</strong> 的作用：作为基准，($\beta$) 衡量 ($\tau_i$) 是否达到预期。过高的 ($\beta$) 可能导致代理过于激进，增加无效迁移；过低的 ($\beta$) 则可能限制性能优化。</li>
<li><strong>$(\lambda)$ 的动态性</strong>：当 ($\lambda = 0$)（无迁移），奖励仅基于当前 ($\tau_i - \beta$)，避免对未发生迁移的场景施加额外惩罚。</li>
</ul>
<h4 id="4-2-替代奖励函数">4.2 替代奖励函数</h4>
<p>论文在 6.3.4 节探讨了基于内存访问延迟（latency）的奖励函数，通过监控每周期的待处理内存请求数近似延迟。实验结果表明：</p>
<ul>
<li>延迟奖励可将平均延迟降低 3.47 倍，但增加了数据收集开销，导致性能略有下降。</li>
<li>DRAM 访问比率奖励更简单且效果更好，适合实时性要求高的场景。</li>
</ul>
<h3 id="5-Q-learning-实现">5. Q-learning 实现</h3>
<p>ArtMem 的 Q-learning 算法基于 Markov 决策过程（MDP），通过迭代更新 Q 表优化迁移策略。其核心流程如下：</p>
<p>初始化 Q 表为 0<br>
初始化状态 $ \tau_{i-1} = k $ (DRAM 访问比率 100%)<br>
while 程序未结束:<br>
根据 $ \tau_{i-1} $ 和 ε-贪心策略选择动作 $ a $<br>
迁移线程根据动作 $ a $ 执行页面迁移<br>
采样线程观测新状态 $ \tau_i $<br>
计算奖励: $ \text{Reward} = \tau_i - \beta + \lambda (\tau_i - \tau_{i-1}) $<br>
更新 Q 值: $ Q(\tau_{i-1}, a) = Q(\tau_{i-1}, a) + \alpha (\text{Reward} + \gamma \max_{a’} Q(\tau_i, a’) - Q(\tau_{i-1}, a)) $<br>
更新状态: $ \tau_{i-1} \leftarrow \tau_i $</p>
<h4 id="5-1-关键超参数">5.1 关键超参数</h4>
<ul>
<li><strong>学习率 ($\alpha$)</strong>：控制新经验对 Q 值的更新幅度。($\alpha = 0.1$) 是最优值，平衡了学习速度和稳定性。</li>
<li><strong>折扣因子 ($\gamma$)</strong>：衡量长期奖励的权重。($\gamma = 0.9$) 能有效平衡短期和长期收益。</li>
<li><strong>探索率 ($\varepsilon$)</strong>：控制探索与利用的比例，($\varepsilon = 0.5$) 提供最佳性能。</li>
<li><strong>迁移间隔</strong>：每 10 秒执行一次迁移（图 15f 建议 5-15 秒为最佳范围），避免过频繁的迁移导致性能下降。</li>
</ul>
<h4 id="5-2-Q-表实现">5.2 Q 表实现</h4>
<ul>
<li>两张 Q 表：
<ul>
<li>热页面阈值 Q 表：12 个状态 × 5 个动作（±8, ±4, 0）。</li>
<li>迁移数量 Q 表：12 个状态 × 9 个动作（0MB 到 2048MB）。</li>
</ul>
</li>
<li><strong>内存开销</strong>：Q 表存储在内核中，内存占用极低（第 6.4 节提到 Q 表计算开销仅为 CPU 的 0.07%）。</li>
<li><strong>初始化</strong>：初始 Q 值为 0，首状态设为 (k = 10)（DRAM 访问比率 100%），反映程序启动时数据加载到 DRAM 的情况。</li>
</ul>
<h3 id="6-RL-与内存系统的集成">6. RL 与内存系统的集成</h3>
<p>ArtMem 通过以下机制将 RL 框架无缝集成到分层内存系统中：</p>
<ul>
<li><strong>采样线程</strong>：
<ul>
<li>使用 PMU 和 PEBS 每 200 次事件采样一次内存访问数据，记录到环形缓冲区。</li>
<li>采样线程更新页面访问频率和 DRAM 访问比率，供 RL 代理计算状态。</li>
<li>采样开销低，仅占 CPU 的 0.02%。</li>
</ul>
</li>
<li><strong>迁移线程</strong>：
<ul>
<li>异步执行页面迁移，基于 RL 代理的动作，从 PM 活跃列表头部迁移页面到 DRAM。</li>
<li>如果 DRAM 空间不足，从 DRAM 非活跃列表尾部降级冷页面。</li>
<li>迁移单位为 2MB 大页面，降低地址转换开销。</li>
</ul>
</li>
<li><strong>交互通道</strong>：
<ul>
<li>通过 Linux 内核的伪文件系统（memory control group）实现环境与代理的交互。</li>
<li>例如，<code>memory_hit_ratio_show</code> 文件提供采样数据，<code>memory_threshold_show</code> 和 <code>memory_hit_on_show</code> 文件传递动作指令。</li>
</ul>
</li>
</ul>
<h3 id="7-RL-的性能与鲁棒性">7. RL 的性能与鲁棒性</h3>
<h4 id="7-1-性能表现">7.1 性能表现</h4>
<ul>
<li><strong>性能提升</strong>：ArtMem 在多种工作负载下实现 35%-172% 的性能提升，平均提升 114%。</li>
<li>工作负载适应性：
<ul>
<li><strong>SSSP 和 CC</strong>：RL 有效识别热区域，性能提升 16%-31%。</li>
<li><strong>DLRM</strong>：通过学习顺序访问模式，提升 10%-19%。</li>
<li><strong>BTree</strong>：性能接近最佳的 Multi-clock，提升 4%-36%。</li>
<li><strong>Liblinear</strong>：初始访问比率下降后快速恢复，平均提升 76%。</li>
</ul>
</li>
<li><strong>迁移效率</strong>：ArtMem 的迁移量比 MEMTIS 少 0.09 倍，减少了不必要迁移。</li>
</ul>
<h4 id="7-2-鲁棒性与泛化能力">7.2 鲁棒性与泛化能力</h4>
<ul>
<li><strong>跨工作负载泛化</strong>：ArtMem 的 Q 表在不同工作负载上仅 7/25 种情况下性能下降超过 10%，表明较强的泛化能力。</li>
<li><strong>快速收敛</strong>：当使用次优 Q 表时，ArtMem 平均需 1-6 次迭代达到 96% 的最优性能。</li>
<li><strong>超参数敏感性</strong>：ArtMem 对超参数（如 ($\alpha$)、($\gamma$)、($\varepsilon)$）的设置较为鲁棒，经验值已接近最优。</li>
</ul>
<h4 id="7-3-算法对比">7.3 算法对比</h4>
<ul>
<li>论文比较了 Q-learning 和 SARSA，结果显示两者性能相近，表明 ArtMem 的框架对 RL 算法选择不敏感，增强了其适用性。</li>
</ul>
<h3 id="8-RL-设计的创新点">8. RL 设计的创新点</h3>
<ol>
<li><strong>系统级状态设计</strong>：通过 DRAM 访问比率简化状态空间，降低计算复杂性。</li>
<li><strong>双 Q 表策略</strong>：分离热页面阈值和迁移数量的控制，增强动作灵活性。</li>
<li><strong>动态奖励函数</strong>：结合访问比率和迁移成本，平衡性能与开销。</li>
<li><strong>低开销集成</strong>：通过异步采样和迁移线程，RL 计算对关键路径的影响最小（采样和 Q 表更新开销分别仅占 0.02% 和 0.07% CPU）。</li>
<li><strong>适应性强</strong>：能够处理动态和混合工作负载，尤其在复杂访问模式下表现出色。</li>
</ol>
<h3 id="9-未来改进方向">9. 未来改进方向</h3>
<ul>
<li><strong>更复杂的奖励函数</strong>：结合延迟、带宽等多维度指标，进一步优化性能（第 6.3.4 节已尝试延迟奖励）。</li>
<li><strong>自适应采样周期</strong>：动态调整采样频率以适应不同工作负载的访问密度。</li>
<li><strong>多代理 RL</strong>：在多节点 NUMA 或 CXL 系统中引入多代理协作，优化全局迁移策略。</li>
<li><strong>深度 RL 扩展</strong>：对于超大规模内存系统，可尝试深度 Q 网络（DQN）以处理更高维的状态空间。</li>
</ul>
<h3 id="10-结论">10. 结论</h3>
<p>ArtMem 的强化学习设计通过 Q-learning 实现了动态、适应性强的页面迁移策略。其简化的状态空间、灵活的动作设计和高效的奖励函数使其在分层内存系统中表现出色。无论是图算法、推荐系统还是内存数据库，ArtMem 都能通过学习优化内存访问性能，同时保持低开销和强鲁棒性。这一设计为 RL 在系统优化领域的应用提供了宝贵经验，值得进一步探索和扩展。</p>
<h3 id="11-架构图分析">11. 架构图分析</h3>
<p>Artem 架构图如下：</p>
<img src="\img\ArtMem architecute.png" alt="ArtMem architecute" style="zoom: 67%;" />
<p>PMU（Performance Monitoring Unit）监控内存访问情况。</p>
<p>ArtMem 总览图：</p>
<img src="\img\overview of ArtMem.png" alt="overview of ArtMem" style="zoom:67%;" />
<p>图中左上角是内存访问次数分布图，记录了每个页面的访问次数。由页面阈值和迁移范围两个参数共同决定了最后的实际迁移范围。</p>
<p>右侧的 DRAM 层和 PM 层都维护了一个基于 LRU 排序的活跃和不活跃的页面队列。也就是架构图中提到的 Page sorting 操作。</p>
<p>异步的迁移线程收到迁移指令之后，从 DRAM 的不活跃列表中从尾部向前进行降级，当 DRAM 空间足够之后，再从 PM 活跃队列头开始依次往上升级。</p>
<p>Q：在实际迁移过程中，是否需要判断当前正在迁移的页面的访问次数是否小于热页面阈值呢？</p>
<p>A：论文中没提，大概率不需要，因此这里的热页面阈值可能只是辅助调整迁移数量参数。</p>
<h2 id="扩展思考">扩展思考</h2>
<h3 id="创新点">创新点</h3>
<ol>
<li>强化学习驱动，具有动态自适应性。</li>
<li>系统级粒度，不对某个具体页面做决策。通过监控系统中 DRAM 的访问比例来调节热页面阈值和迁移数量的参数。</li>
<li>存储空间压缩率高。指数桶存储页面访问分布，利用 Linux 大页的 struct page 中未使用字段存储页面访问信息。</li>
<li>用户空间 RL 通过伪文件系统与操作系统交互。</li>
<li>异步处理。采样线程和页面迁移线程都在后天异步执行，不影响主 IO 性能。</li>
</ol>
<h2 id="关联文章">关联文章</h2>
<ol>
<li>CHROME: Concurrency-Aware Holistic Cache Management Framework with Online Reinforcement Learning</li>
</ol>
<p>利用强化学习对缓存行为做决策。</p>
<h2 id="待更新内容">待更新内容</h2>
<ol>
<li>结合 IO 路径再捋一下 RL 具体如何发挥作用</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://lingwu-hb.github.io">Bo Han</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://lingwu-hb.github.io/2025/07/04/AICache/thirdStage/RL-paper-survey/">https://lingwu-hb.github.io/2025/07/04/AICache/thirdStage/RL-paper-survey/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AE%9E%E4%B9%A0%E9%A1%B9%E7%9B%AE/">实习项目</a><a class="post-meta__tags" href="/tags/algorithm/">algorithm</a><a class="post-meta__tags" href="/tags/RL/">RL</a></div><div class="post-share"><div class="social-share" data-image="/img/yaojie.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/03/AICache/thirdStage/tsPrefetchus/" title="tsPrefetchus"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">tsPrefetchus</div></div><div class="info-2"><div class="info-item-1">第三阶段需要在 ocf 中实现的预取器有以下几个关键点：  预取出来的 IO 会如何进行处理？会不会和原 IO 串行处理，从而影响原 IO？  空间上会抢占 cache 的空间；时间上，若生成预取 IO 的速度太慢，将会影响下一个原 IO 的处理速度。  该预取器集成了时间和空间预取器？分别而言，时间和空间预取器各自是如何展开工作的呢？  详见下文 Mithril 和 OBL tsPrefetchus 预取器 概述 tsPrefetchus 是一个混合预取器，它结合了两种不同类型的预取策略：  顺序预取器（sequential prefetcher）：如** OBL**, AMP, Leap 等 历史预取器（history prefetcher）：如 Mithril, PG 等  这个预取器的核心思想是动态调整这两种预取策略的权重，以适应不同的访问模式。 工作原理 混合预取策略 tsPrefetchus...</div></div></div></a><a class="pagination-related" href="/2025/07/09/AICache/thirdStage/Mithril-intro/" title="Mithril intro"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">Mithril intro</div></div><div class="info-2"><div class="info-item-1">Mithril 算法数据结构 rec_mining_t 数据结构 rec_mining_t 是 Mithril 算法中用于记录和挖掘访问模式的核心数据结构，它包含以下关键组件： 主要组件    组件 类型 描述     hashtable GHashTable* 哈希表，存储块相关信息。键为块号，值为行号（指向记录表或挖掘表）。- 正值：指向记录表- 负值：指向挖掘表   recording_table gint64* 记录表，结构为 N*(min_support/4+1) 数组。- 其中 4 是一个 64 位整数中存储的时间戳数量- N 是记录表中的条目数- 加 1 是为了标签   rtable_row_len gint8 记录表的行长度，当前为 min_support/4 + 1   n_rows_in_rtable gint64 记录表中的行数，决定记录表可以存储多少块   rtable_cur_row gint64 记录表中的当前行号   mtable_row_len gint8 挖掘表的行长度，当前为 max_support/4 +...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/02/03/AICache/Ceph%E9%83%A8%E7%BD%B2/" title="Ceph部署"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-03</div><div class="info-item-2">Ceph部署</div></div><div class="info-2"><div class="info-item-1">Ceph Monitor职责  维护集群状态图（Cluster Map），Cluster Map为全局的元数据，包括以下信息:   OSD Map	记录所有 OSD 节点的状态（如在线/离线）、存储容量、数据分布规则（CRUSH 算法配置）。 MON Map	记录 Monitor 节点自身的列表和地址。 PG Map	管理 Placement Group（PG）的映射关系（PG 是数据分片逻辑单元）。 MDS Map（仅当使用 CephFS 时）	记录 Metadata Server 的状态。    管理集群的 Paxos 共识，确保Cluster Map的强一致性。   处理客户端请求 客户端（如 RBD、RGW、CephFS）首次连接集群时，会从 Monitor 获取最新的 Cluster Map，用于确定数据的读写位置（如 OSD 地址）。客户端后续操作直接与 OSD 通信，无需持续依赖 Monitor（除非 Cluster Map 更新）。   监控集群健康状态   管理身份认证与权限   协调 PG 状态变更   处理配置变更 1ceph-deploy mon...</div></div></div></a><a class="pagination-related" href="/2025/06/29/AICache/tsPrefetcher%20%E8%B0%83%E7%A0%94/" title="tsPrefetcher 调研"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-29</div><div class="info-item-2">tsPrefetcher 调研</div></div><div class="info-2"><div class="info-item-1">有以下几个关键点：  预取出来的 IO 会如何进行处理？会不会和原 IO 串行处理，从而影响原 IO？  空间上会抢占 cache 的空间；时间上，若生成预取 IO 的速度太慢，将会影响下一个原 IO 的处理速度。  该预取器集成了时间和空间预取器？分别而言，时间和空间预取器各自是如何展开工作的呢？  详见下文 Mithril 和 OBL tsPrefetchus 预取器 概述 tsPrefetchus 是一个混合预取器，它结合了两种不同类型的预取策略：  顺序预取器（sequential prefetcher）：如 OBL, AMP, Leap 等 历史预取器（history prefetcher）：如 Mithril, PG 等  这个预取器的核心思想是动态调整这两种预取策略的权重，以适应不同的访问模式。 工作原理 混合预取策略 tsPrefetchus...</div></div></div></a><a class="pagination-related" href="/2025/06/29/AICache/%E4%B8%80%E4%BA%8C%E9%98%B6%E6%AE%B5%E6%9D%90%E6%96%99%E6%B1%87%E6%80%BB/" title="一二阶段材料汇总"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-29</div><div class="info-item-2">一二阶段材料汇总</div></div><div class="info-2"><div class="info-item-1">一阶段 在 ocf 中实现二次准入策略。 动机 trace 中存在大量只会访问一次的请求，用二次准入过滤掉这些请求，防止其污染缓存空间。 技术点 将每个请求划分成若干个 4K 块，然后对每个 4K 块进行哈希处理，判断该 4K 块之前是否出现过。如果某个请求中，之前出现过的 4K 块的数量超过阈值，则该请求准入；否则，该请求不予准入。 核心代码 12345678910111213141516171819202122232425bool ocf_history_check_second_chance(uint64_t addr, uint64_t size) &#123;    // 计算页面对齐的地址    uint64_t start_addr = PAGE_ALIGN_DOWN(addr);    uint64_t end_addr = PAGE_ALIGN_DOWN(addr + size - 1);    uint64_t total_pages = PAGES_IN_REQ(start_addr, end_addr);    uint64_t hit_pages =...</div></div></div></a><a class="pagination-related" href="/2025/03/18/AICache/%E4%BA%8C%E6%AC%A1%E5%87%86%E5%85%A5IO%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95/" title="二次准入IO过滤算法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-18</div><div class="info-item-2">二次准入IO过滤算法</div></div><div class="info-2"><div class="info-item-1">问题 改为 4K 后，通过火焰图分析，发现历史哈希表的插入和查找过程非常耗时，分别为整个系统用时的 19.3% 和 34.11%。 打印出哈希表的状态发现，哈希表中冲突链的个数过多。 初步分析，因为是因为初始的时候哈希表的长度过小，并且 IO 涉及的 4K 块访问地址跨度过大，导致此问题发生。 改进想法  增加哈希表初始化的大小 限制冲突链表的长度值  </div></div></div></a><a class="pagination-related" href="/2025/02/23/system/C%E8%AF%AD%E8%A8%80%E5%AE%8F%E5%AE%9A%E4%B9%89%E9%80%9A%E8%BF%87%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F%E8%8E%B7%E5%8F%96%E7%B1%BB%E6%8C%87%E9%92%88%E6%9C%80%E4%BC%98%E8%A7%A3/" title="C语言宏定义通过成员变量获取类指针最优解"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-23</div><div class="info-item-2">C语言宏定义通过成员变量获取类指针最优解</div></div><div class="info-2"><div class="info-item-1">问题简介 最近在看开源 OCF 源码的时候，发现了一个 C 语言宏定义的常见使用技巧。从初见的不解，到了解之后的惊叹，不得不感叹于底层开发人员关于性能的极致追求！ 在编程开发中，经常需要进行变量之间的类型转换操作。一个类 A 中存在类型为B 的成员变量。假设现在我拥有一个类型为 B 的变量 v1，我需要得到一个类型为 A 的变量 v2，同时 v2-&gt;B 就为变量 v1。 方法一 一般来说，对于此类问题，熟悉 C++ 的初学者会考虑采用以下的方法实现： 12345678910111213141516// 用宏定义实现此功能！#define CONVERT_B_TO_A(v1) A(v1)class B &#123;    // B 类的定义&#125;;class A &#123;public:    B b;    A(const B&amp; b_val) : b(b_val) &#123;&#125;&#125;;int main() &#123;    B v1;    A v2 = CONVERT_B_TO_A(v1);  // 使用宏进行转换    return...</div></div></div></a><a class="pagination-related" href="/2025/04/02/algo/algorithm-notebook/" title="algorithm notebook"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-02</div><div class="info-item-2">algorithm notebook</div></div><div class="info-2"><div class="info-item-1">算法笔记 数据结构类 tip string 类常用方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123;    //字符数组转字符串    char a[100];    string s5(a);    cout&lt;&lt;s5&lt;&lt;endl; //输出World!    //8、字符串的子串    s1 = &quot;hello World!&quot;;    s2 = s1.substr(2,5);    cout&lt;&lt;s2&lt;&lt;endl; //输出 llo W 从下标2开始 截取5个字符    s2 = s1.substr(3);    cout&lt;&lt;s2&lt;&lt;endl; //输出 llo W 从下标3开始...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/yaojie.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Bo Han</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">33</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">35</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-ArtMem"><span class="toc-number">1.</span> <span class="toc-text">1. ArtMem</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%EF%BC%9A"><span class="toc-number">1.1.</span> <span class="toc-text">背景：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E7%9B%91%E6%8E%A7"><span class="toc-number">1.1.1.</span> <span class="toc-text">内存访问监控</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A1%B5%E8%BF%81%E7%A7%BB%E6%8C%87%E6%A0%87"><span class="toc-number">1.1.2.</span> <span class="toc-text">页迁移指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DRAM-%E5%BF%AB%E9%80%9F%E8%AE%BF%E9%97%AE%E6%AF%94%E4%BE%8B"><span class="toc-number">1.1.3.</span> <span class="toc-text">DRAM 快速访问比例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A1%B5%E8%BF%81%E7%A7%BB%E8%8C%83%E5%9B%B4"><span class="toc-number">1.1.4.</span> <span class="toc-text">页迁移范围</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ArtMem-%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.2.</span> <span class="toc-text">ArtMem 设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%A6%82%E8%BF%B0"><span class="toc-number">1.2.1.</span> <span class="toc-text">1. 强化学习框架概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%8A%B6%E6%80%81%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.2.2.</span> <span class="toc-text">2. 状态设计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E5%AE%9A%E4%B9%89"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">2.1 定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E8%AE%BE%E8%AE%A1%E8%80%83%E9%87%8F"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">2.2 设计考量</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%8A%A8%E4%BD%9C%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.2.3.</span> <span class="toc-text">3. 动作设计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-%E5%8A%A8%E4%BD%9C%E7%A9%BA%E9%97%B4%E4%BC%98%E5%8C%96"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">3.1 动作空间优化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%A5%96%E5%8A%B1%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.2.4.</span> <span class="toc-text">4. 奖励设计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-%E5%A5%96%E5%8A%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90"><span class="toc-number">1.2.4.1.</span> <span class="toc-text">4.1 奖励函数解析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-%E6%9B%BF%E4%BB%A3%E5%A5%96%E5%8A%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.2.4.2.</span> <span class="toc-text">4.2 替代奖励函数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Q-learning-%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.2.5.</span> <span class="toc-text">5. Q-learning 实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-%E5%85%B3%E9%94%AE%E8%B6%85%E5%8F%82%E6%95%B0"><span class="toc-number">1.2.5.1.</span> <span class="toc-text">5.1 关键超参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-Q-%E8%A1%A8%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.2.5.2.</span> <span class="toc-text">5.2 Q 表实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-RL-%E4%B8%8E%E5%86%85%E5%AD%98%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%9B%86%E6%88%90"><span class="toc-number">1.2.6.</span> <span class="toc-text">6. RL 与内存系统的集成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-RL-%E7%9A%84%E6%80%A7%E8%83%BD%E4%B8%8E%E9%B2%81%E6%A3%92%E6%80%A7"><span class="toc-number">1.2.7.</span> <span class="toc-text">7. RL 的性能与鲁棒性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#7-1-%E6%80%A7%E8%83%BD%E8%A1%A8%E7%8E%B0"><span class="toc-number">1.2.7.1.</span> <span class="toc-text">7.1 性能表现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-2-%E9%B2%81%E6%A3%92%E6%80%A7%E4%B8%8E%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B"><span class="toc-number">1.2.7.2.</span> <span class="toc-text">7.2 鲁棒性与泛化能力</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-3-%E7%AE%97%E6%B3%95%E5%AF%B9%E6%AF%94"><span class="toc-number">1.2.7.3.</span> <span class="toc-text">7.3 算法对比</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-RL-%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%88%9B%E6%96%B0%E7%82%B9"><span class="toc-number">1.2.8.</span> <span class="toc-text">8. RL 设计的创新点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-%E6%9C%AA%E6%9D%A5%E6%94%B9%E8%BF%9B%E6%96%B9%E5%90%91"><span class="toc-number">1.2.9.</span> <span class="toc-text">9. 未来改进方向</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-%E7%BB%93%E8%AE%BA"><span class="toc-number">1.2.10.</span> <span class="toc-text">10. 结论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-%E6%9E%B6%E6%9E%84%E5%9B%BE%E5%88%86%E6%9E%90"><span class="toc-number">1.2.11.</span> <span class="toc-text">11. 架构图分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%A9%E5%B1%95%E6%80%9D%E8%80%83"><span class="toc-number">1.3.</span> <span class="toc-text">扩展思考</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E6%96%B0%E7%82%B9"><span class="toc-number">1.3.1.</span> <span class="toc-text">创新点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E8%81%94%E6%96%87%E7%AB%A0"><span class="toc-number">1.4.</span> <span class="toc-text">关联文章</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BE%85%E6%9B%B4%E6%96%B0%E5%86%85%E5%AE%B9"><span class="toc-number">1.5.</span> <span class="toc-text">待更新内容</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/09/AICache/thirdStage/Mithril-intro/" title="Mithril intro">Mithril intro</a><time datetime="2025-07-09T08:40:28.000Z" title="Created 2025-07-09 16:40:28">2025-07-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/04/AICache/thirdStage/RL-paper-survey/" title="RL paper survey">RL paper survey</a><time datetime="2025-07-04T02:03:02.000Z" title="Created 2025-07-04 10:03:02">2025-07-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/03/AICache/thirdStage/tsPrefetchus/" title="tsPrefetchus">tsPrefetchus</a><time datetime="2025-07-03T06:21:16.000Z" title="Created 2025-07-03 14:21:16">2025-07-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/03/AICache/thirdStage/cache-and-request-contrast/" title="cache and request contrast">cache and request contrast</a><time datetime="2025-07-03T01:20:11.000Z" title="Created 2025-07-03 09:20:11">2025-07-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/01/AICache/thirdStage/spdk/" title="spdk">spdk</a><time datetime="2025-07-01T01:55:48.000Z" title="Created 2025-07-01 09:55:48">2025-07-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Bo Han</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.2.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>